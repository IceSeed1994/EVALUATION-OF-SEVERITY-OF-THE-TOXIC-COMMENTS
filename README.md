Abstractâ€”The evaluation of toxic comment severity in online platforms demands efficient methods. Deep Learning (DL) models offer an automated approach by understanding language patterns
and context. DL models use the steps of dataset gathering, annotation, and preprocessing to determine the severity of toxic comments. Scalable options for automated content moderation
and resource prioritization are offered by DL models. By identifying the underlying traits of toxic comments, they support interventions, guidelines, and education. DL models offer
automated solutions for content moderation and are promising in assessing the severity of toxic comments. Fair evaluations depend on addressing biases and ensuring model interpretability.
Continued research and collaboration will foster a safer online environment.

